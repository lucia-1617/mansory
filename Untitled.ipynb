{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc71ad27-be8c-40a5-9458-d60ae3e47d01",
   "metadata": {},
   "source": [
    "**Entorno (TF/Keras, seeds, GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e34b04-d245-4ccf-81a3-69113ce5abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]\n",
      "TensorFlow: 2.20.0\n",
      "Keras (tf.keras): 3.11.3\n"
     ]
    }
   ],
   "source": [
    "# Celda 0: entorno\n",
    "import os, random, json, math, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras (tf.keras):\", keras.__version__)\n",
    "\n",
    "# Semillas para reproducibilidad\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Limitar hilos CPU (opcional; ayuda en Windows a que no se “trabe”)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "\n",
    "# Habilitar growth de memoria GPU si existe\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU disponible:\", gpus)\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo activar memory_growth:\", e)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e5210-193a-492a-a297-0bc75ac62d62",
   "metadata": {},
   "source": [
    "**Parámetros, rutas y semilla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7554bb5-ec5a-4356-bf0c-032f690db64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\User\\mansory\n",
      "TRAIN_DIR   : C:\\Users\\User\\mansory\\train\n",
      "VAL_DIR     : C:\\Users\\User\\mansory\\test\n",
      "REAL_DIR    : C:\\Users\\User\\mansory\\real\n",
      "MODEL_DIR   : C:\\Users\\User\\mansory\\modelos\n",
      "LOGS_DIR    : C:\\Users\\User\\mansory\\modelos\\logs\n",
      "MODEL_REGULAR: C:\\Users\\User\\mansory\\modelos\\modelo_mansory.keras\n",
      "MODEL_BEST95 : C:\\Users\\User\\mansory\\modelos\\modelo_mansory_95.keras\n",
      "CLASSES_JSON : C:\\Users\\User\\mansory\\modelos\\classes.json\n"
     ]
    }
   ],
   "source": [
    "# ==== Celda 2: parámetros y rutas ====\n",
    "from pathlib import Path\n",
    "\n",
    "# Detecta automáticamente la carpeta del proyecto.\n",
    "# Si este cuaderno NO está dentro de \"mansory\", usa el fallback explícito.\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"train\").exists():\n",
    "    PROJECT_ROOT = Path(r\"C:\\Users\\User\\mansory\")  # ← CAMBIA si tu ruta es distinta\n",
    "\n",
    "# Directorios de datos\n",
    "TRAIN_DIR = PROJECT_ROOT / \"train\"   # entrenamiento\n",
    "VAL_DIR   = PROJECT_ROOT / \"test\"    # validación/pruebas\n",
    "REAL_DIR  = PROJECT_ROOT / \"real\"    # (opcional) uso posterior\n",
    "\n",
    "# Directorio de modelos y logs\n",
    "MODEL_DIR = PROJECT_ROOT / \"modelos\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOGS_DIR = MODEL_DIR / \"logs\"\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Archivos de modelo y clases\n",
    "MODEL_REGULAR = MODEL_DIR / \"modelo_mansory.keras\"       # mejor por val_accuracy\n",
    "MODEL_BEST95  = MODEL_DIR / \"modelo_mansory_95.keras\"    # mejor ≥95% (si se alcanza)\n",
    "CLASSES_JSON  = MODEL_DIR / \"classes.json\"               # nombres de clases\n",
    "\n",
    "# Mostrar para verificación\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT.resolve())\n",
    "print(\"TRAIN_DIR   :\", TRAIN_DIR)\n",
    "print(\"VAL_DIR     :\", VAL_DIR)\n",
    "print(\"REAL_DIR    :\", REAL_DIR)\n",
    "print(\"MODEL_DIR   :\", MODEL_DIR)\n",
    "print(\"LOGS_DIR    :\", LOGS_DIR)\n",
    "print(\"MODEL_REGULAR:\", MODEL_REGULAR)\n",
    "print(\"MODEL_BEST95 :\", MODEL_BEST95)\n",
    "print(\"CLASSES_JSON :\", CLASSES_JSON)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf9aa6-0f1a-46ed-94c2-ac48463d4f2e",
   "metadata": {},
   "source": [
    "**Escaneo de carpetas, construcción de datasets y class weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7f004c-e6a5-4a1a-819a-afbc18ad02de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: 10 ['compresion_vertical_Grave', 'compresion_vertical_Leve', 'compresion_vertical_Moderada', 'friccion_cortante_escalonada_Grave', 'friccion_cortante_escalonada_Leve', 'friccion_cortante_escalonada_Moderada', 'sin_grietas', 'tension_diagonal_inclinadas_Grave', 'tension_diagonal_inclinadas_Leve', 'tension_diagonal_inclinadas_Moderada']\n",
      "Clases guardadas en C:\\Users\\User\\mansory\\modelos\\classes.json\n",
      "Recuento original por clase: {'compresion_vertical_Grave': 279, 'compresion_vertical_Leve': 22, 'compresion_vertical_Moderada': 688, 'friccion_cortante_escalonada_Grave': 330, 'friccion_cortante_escalonada_Leve': 28, 'friccion_cortante_escalonada_Moderada': 1959, 'sin_grietas': 23553, 'tension_diagonal_inclinadas_Grave': 18, 'tension_diagonal_inclinadas_Leve': 3, 'tension_diagonal_inclinadas_Moderada': 231}\n"
     ]
    }
   ],
   "source": [
    "# ==== Celda 3B: dataset balanceado + val ====\n",
    "from pathlib import Path\n",
    "import glob, os, json, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# --- usa lo que ya tengas definido ---\n",
    "# TRAIN_DIR, VAL_DIR (o TEST_DIR), IMG_SIZE, BATCH_SIZE\n",
    "# MODEL_DIR, CLASSES_JSON ya vienen de tu Celda 2\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "random.seed(42)\n",
    "\n",
    "IMG_SIZE = (160, 160)  # debe coincidir con tu modelo\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# -------- escaneo de carpetas -> nombres de clases + rutas ----------\n",
    "def canonical_name(parent, child=None):\n",
    "    norm = lambda s: s.strip().replace(\" \", \"_\")\n",
    "    p = norm(parent)\n",
    "    if p.lower().startswith(\"sin\"):\n",
    "        return \"sin_grietas\"\n",
    "    return f\"{p}_{norm(child)}\"\n",
    "\n",
    "def scan_leaf_dirs(root: Path):\n",
    "    # Devuelve: class_names (orden estable) y lista de (files, label)\n",
    "    root = Path(root)\n",
    "    class_to_files = {}\n",
    "    for ptype in sorted([d for d in root.iterdir() if d.is_dir()]):\n",
    "        if ptype.name.lower().startswith(\"sin\"):\n",
    "            files = sum([glob.glob(str(ptype / f\"*{ext}\")) for ext in [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]], [])\n",
    "            if files:\n",
    "                cname = \"sin_grietas\"\n",
    "                class_to_files.setdefault(cname, []).extend(sorted(files))\n",
    "        else:\n",
    "            for sev in sorted([d for d in ptype.iterdir() if d.is_dir()]):\n",
    "                files = sum([glob.glob(str(sev / f\"*{ext}\")) for ext in [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]], [])\n",
    "                if files:\n",
    "                    cname = canonical_name(ptype.name, sev.name)\n",
    "                    class_to_files.setdefault(cname, []).extend(sorted(files))\n",
    "    class_names = sorted(class_to_files.keys())\n",
    "    files = []\n",
    "    labels = []\n",
    "    for i, cname in enumerate(class_names):\n",
    "        fs = class_to_files[cname]\n",
    "        files.extend(fs)\n",
    "        labels.extend([i]*len(fs))\n",
    "    return class_names, files, labels, class_to_files\n",
    "\n",
    "# --- escanea train y val ---\n",
    "class_names, train_files_all, train_labels_all, train_map = scan_leaf_dirs(Path(TRAIN_DIR))\n",
    "_,          val_files_all,   val_labels_all,   _         = scan_leaf_dirs(Path(VAL_DIR))\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(\"Clases:\", NUM_CLASSES, class_names)\n",
    "\n",
    "# ---- guarda clases (para inferencia) ----\n",
    "CLASSES_JSON.write_text(json.dumps({\"class_names\": class_names}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"Clases guardadas en\", CLASSES_JSON)\n",
    "\n",
    "# ------------- muestreo balanceado para train ------------------\n",
    "# objetivo por clase / época\n",
    "TARGET_PER_CLASS = 300\n",
    "CAP_SIN_GRIETAS  = 600  # para sin_grietas permitimos más si quieres\n",
    "IMG_EXTS = [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]\n",
    "\n",
    "def make_aug_layer():\n",
    "    return keras.Sequential([\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.08),\n",
    "        keras.layers.RandomZoom(0.2),\n",
    "        keras.layers.RandomContrast(0.2),\n",
    "        keras.layers.RandomBrightness(0.2),\n",
    "    ], name=\"aug\")\n",
    "\n",
    "AUG = make_aug_layer()\n",
    "\n",
    "def load_preprocess(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = (img - 0.5) * 2.0\n",
    "    y   = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "    return img, y\n",
    "\n",
    "def load_preprocess_val(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = (img - 0.5) * 2.0\n",
    "    y   = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "    return img, y\n",
    "\n",
    "# construir datasets por clase con oversampling + augment\n",
    "per_class_datasets = []\n",
    "counts = []\n",
    "for cid, cname in enumerate(class_names):\n",
    "    paths = train_map[cname]\n",
    "    n = len(paths)\n",
    "    counts.append(n)\n",
    "    tgt = CAP_SIN_GRIETAS if cname == \"sin_grietas\" else TARGET_PER_CLASS\n",
    "    if n >= tgt:\n",
    "        chosen = random.sample(paths, tgt)\n",
    "    else:\n",
    "        # oversampling con reposición\n",
    "        chosen = [random.choice(paths) for _ in range(tgt)]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((chosen, [cid]*len(chosen)))\n",
    "    ds = ds.shuffle(len(chosen), seed=42)\n",
    "    ds = ds.map(lambda p,l: load_preprocess(p,l), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(lambda x,y: (AUG(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "    per_class_datasets.append(ds.repeat())\n",
    "\n",
    "print(\"Recuento original por clase:\", dict(zip(class_names, counts)))\n",
    "\n",
    "# mezcla balanceada (cada clase aporta ~1/NUM_CLASSES)\n",
    "train_ds = tf.data.Dataset.sample_from_datasets(per_class_datasets, weights=[1.0/NUM_CLASSES]*NUM_CLASSES, seed=42)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# ----- val ds (sin augment, sin balance) -----\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_files_all, val_labels_all))\n",
    "val_ds = val_ds.map(load_preprocess_val, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890c02b-7915-4624-a60c-c271a782e71e",
   "metadata": {},
   "source": [
    "**Modelo (MobileNetV2 + cabeza densa)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4ba1c-ab86-4209-9100-603169ab1e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: [7.500e-02 9.410e-01 3.100e-02 6.400e-02 7.400e-01 1.200e-02 2.000e-03\n",
      " 1.150e+00 6.895e+00 9.100e-02]\n",
      "Epoch 1/30\n",
      "  37373/Unknown \u001b[1m31064s\u001b[0m 831ms/step - accuracy: 0.1664 - loss: 0.5181"
     ]
    }
   ],
   "source": [
    "# ==== Celda 4B: Focal Loss + entrenamiento ====\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# calcula alpha (Cui et al. \"effective number of samples\")\n",
    "beta = 0.9999\n",
    "counts_arr = np.array([len(train_map[c]) for c in class_names], dtype=np.float32)\n",
    "eff_num = (1 - np.power(beta, counts_arr)) / (1 - beta)\n",
    "alpha = (np.sum(eff_num) / eff_num)\n",
    "alpha = alpha / np.mean(alpha)  # normaliza\n",
    "alpha_tf = tf.constant(alpha, dtype=tf.float32)\n",
    "print(\"alpha:\", np.round(alpha, 3))\n",
    "\n",
    "def categorical_focal_loss(alpha_vec, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        eps = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1 - y_pred, gamma) * alpha_vec\n",
    "        return tf.reduce_sum(weight * ce, axis=-1)\n",
    "    return loss\n",
    "\n",
    "# modelo (puedes mantener tu arquitectura actual si ya la tienes)\n",
    "base = keras.applications.MobileNetV2(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=(*IMG_SIZE,3)\n",
    ")\n",
    "base.trainable = False  # warmup\n",
    "x = keras.layers.GlobalAveragePooling2D()(base.output)\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "out = keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = keras.Model(base.input, out, name=\"mansory_mobilenetv2\")\n",
    "\n",
    "loss_fn = categorical_focal_loss(alpha_tf, gamma=2.0)\n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks\n",
    "es  = keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "rlr = keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=\"val_accuracy\")\n",
    "ck  = keras.callbacks.ModelCheckpoint(str(MODEL_REGULAR), monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True, save_weights_only=False)\n",
    "\n",
    "class Save95(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (logs or {}).get(\"val_accuracy\", 0) >= 0.95:\n",
    "            self.model.save(str(MODEL_BEST95), include_optimizer=False)\n",
    "            print(f\"\\n✅ Guardado {MODEL_BEST95} (val_acc ≥ 95%)\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[es, rlr, ck, Save95()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# unfreeze fino (opcional): afina últimas capas si val_acc se estanca\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-40]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "history2 = model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=10, callbacks=[es, rlr, ck, Save95()], verbose=1\n",
    ")\n",
    "\n",
    "# guardamos clases de nuevo por si entrenas desde cero\n",
    "CLASSES_JSON.write_text(json.dumps({\"class_names\": class_names}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"\\nClases guardadas en\", CLASSES_JSON)\n",
    "print(\"Modelo mejor por val_acc en:\", MODEL_REGULAR)\n",
    "if Path(MODEL_BEST95).exists():\n",
    "    print(\"También se guardó:\", MODEL_BEST95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caef3ea-bda2-4d19-a3bc-f515a4caf757",
   "metadata": {},
   "source": [
    "**Callbacks (EarlyStopping, LR, Checkpoints, ≥95%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f40f8029-d385-4000-bd95-45984475959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de clases en JSON: 10 → C:\\Users\\User\\mansory\\classes.json\n",
      "Modelos encontrados:\n",
      " - C:\\Users\\User\\mansory\\modelo_mansory.keras\n",
      " - C:\\Users\\User\\mansory\\modelo_mansory_95.keras\n",
      " - C:\\Users\\User\\mansory\\modelos\\modelo_mansory.keras\n",
      "   modelo_mansory.keras: salidas=4, input=(160, 160, 3)\n",
      "   modelo_mansory_95.keras: salidas=10, input=(224, 224, 3)\n",
      "\n",
      "✅ Usaré: C:\\Users\\User\\mansory\\modelo_mansory_95.keras\n",
      "   Tamaño de entrada esperado: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "# Carpeta base donde están tus archivos (ajústala si fuera distinto)\n",
    "BASE = Path(r\"C:\\Users\\User\\mansory\")\n",
    "\n",
    "# 1) Cargar clases (prioriza el classes.json de la raíz)\n",
    "CLASSES_JSON = BASE / \"classes.json\"\n",
    "if not CLASSES_JSON.exists():\n",
    "    CLASSES_JSON = BASE / \"modelos\" / \"classes.json\"\n",
    "class_names = json.loads(CLASSES_JSON.read_text(encoding=\"utf-8\"))[\"class_names\"]\n",
    "print(\"Nº de clases en JSON:\", len(class_names), \"→\", CLASSES_JSON)\n",
    "\n",
    "# 2) Listar modelos .keras (en raíz y en /modelos)\n",
    "keras_files = [*BASE.glob(\"*.keras\"), *(BASE/\"modelos\").glob(\"*.keras\")]\n",
    "print(\"Modelos encontrados:\")\n",
    "for kf in keras_files: print(\" -\", kf)\n",
    "\n",
    "# 3) Cargar cada modelo y quedarnos con el que tenga el mismo nº de salidas\n",
    "picked = None\n",
    "picked_in_size = None\n",
    "for kf in keras_files:\n",
    "    try:\n",
    "        m = keras.models.load_model(kf)\n",
    "        num_out = m.output_shape[-1]\n",
    "        in_shape = m.input_shape[1:4]  # (H, W, C)\n",
    "        print(f\"   {kf.name}: salidas={num_out}, input={in_shape}\")\n",
    "        if num_out == len(class_names):\n",
    "            picked = kf\n",
    "            picked_in_size = (int(in_shape[0]), int(in_shape[1]))\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"   {kf.name}: no se pudo cargar -> {e}\")\n",
    "\n",
    "assert picked is not None, (\n",
    "    \"No encontré un .keras con el mismo número de clases que tu JSON. \"\n",
    "    \"Deja solo el modelo correcto (de 10 clases) o borra/renombra los viejos.\"\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Usaré:\", picked)\n",
    "print(\"   Tamaño de entrada esperado:\", picked_in_size)\n",
    "\n",
    "# Deja el modelo y tamaño listos para la siguiente celda\n",
    "MODEL_PATH = picked\n",
    "TARGET_SIZE = picked_in_size\n",
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fc1c68a-9278-4ef1-9d1f-a8acd1d42c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de grieta: sin grietas\n",
      "Severidad: -\n"
     ]
    }
   ],
   "source": [
    "def split_type_severity(name: str):\n",
    "    name = name.strip()\n",
    "    if name.lower().replace(\"__\", \"_\") == \"sin_grietas\":\n",
    "        return \"sin grietas\", \"-\"\n",
    "    parts = name.split(\"_\")\n",
    "    # La última palabra es la severidad, lo demás es el tipo\n",
    "    severidad = parts[-1]\n",
    "    tipo = \" \".join(parts[:-1]).replace(\"_\", \" \")\n",
    "    return tipo, severidad\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = load_img(img_path, target_size=TARGET_SIZE)\n",
    "    x = img_to_array(img)\n",
    "    x = x / 255.0\n",
    "    x = (x - 0.5) * 2.0\n",
    "    x = np.expand_dims(x, 0)\n",
    "\n",
    "    pred = model.predict(x, verbose=0)\n",
    "    pred_id = int(np.argmax(pred[0]))\n",
    "    if pred_id >= len(class_names):\n",
    "        raise RuntimeError(\n",
    "            f\"pred_id {pred_id} fuera de rango para {len(class_names)} clases. \"\n",
    "            \"Asegúrate de que el modelo y el JSON corresponden.\"\n",
    "        )\n",
    "    tipo, sev = split_type_severity(class_names[pred_id])\n",
    "    print(f\"Tipo de grieta: {tipo}\\nSeveridad: {sev}\")\n",
    "\n",
    "# Prueba con tu imagen (ajústala si quieres otra)\n",
    "predict_image(BASE / \"grieta-muro.jpg\")\n",
    "# Ejemplos:\n",
    "# predict_image(BASE / \"test\" / \"compresion_vertical_Grave\" / \"55.jpg\")\n",
    "# predict_image(BASE / \"grieta-muro.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78d471-84a4-4331-a595-41c5a3ecf16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mansorytf]",
   "language": "python",
   "name": "conda-env-mansorytf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
