{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc71ad27-be8c-40a5-9458-d60ae3e47d01",
   "metadata": {},
   "source": [
    "**Entorno (TF/Keras, seeds, GPU)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e34b04-d245-4ccf-81a3-69113ce5abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 0: entorno\n",
    "import os, random, json, math, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras (tf.keras):\", keras.__version__)\n",
    "\n",
    "# Semillas para reproducibilidad\n",
    "SEED = 1337\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Limitar hilos CPU (opcional; ayuda en Windows a que no se ‚Äútrabe‚Äù)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "\n",
    "# Habilitar growth de memoria GPU si existe\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU disponible:\", gpus)\n",
    "    except Exception as e:\n",
    "        print(\"No se pudo activar memory_growth:\", e)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17e5210-193a-492a-a297-0bc75ac62d62",
   "metadata": {},
   "source": [
    "**Par√°metros, rutas y semilla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7554bb5-ec5a-4356-bf0c-032f690db64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Celda 2: par√°metros y rutas ====\n",
    "from pathlib import Path\n",
    "\n",
    "# Detecta autom√°ticamente la carpeta del proyecto.\n",
    "# Si este cuaderno NO est√° dentro de \"mansory\", usa el fallback expl√≠cito.\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"train\").exists():\n",
    "    PROJECT_ROOT = Path(r\"C:\\Users\\User\\mansory\")  # ‚Üê CAMBIA si tu ruta es distinta\n",
    "\n",
    "# Directorios de datos\n",
    "TRAIN_DIR = PROJECT_ROOT / \"train\"   # entrenamiento\n",
    "VAL_DIR   = PROJECT_ROOT / \"test\"    # validaci√≥n/pruebas\n",
    "REAL_DIR  = PROJECT_ROOT / \"real\"    # (opcional) uso posterior\n",
    "\n",
    "# Directorio de modelos y logs\n",
    "MODEL_DIR = PROJECT_ROOT / \"modelos\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOGS_DIR = MODEL_DIR / \"logs\"\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Archivos de modelo y clases\n",
    "MODEL_REGULAR = MODEL_DIR / \"modelo_mansory.keras\"       # mejor por val_accuracy\n",
    "MODEL_BEST95  = MODEL_DIR / \"modelo_mansory_95.keras\"    # mejor ‚â•95% (si se alcanza)\n",
    "CLASSES_JSON  = MODEL_DIR / \"classes.json\"               # nombres de clases\n",
    "\n",
    "# Mostrar para verificaci√≥n\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT.resolve())\n",
    "print(\"TRAIN_DIR   :\", TRAIN_DIR)\n",
    "print(\"VAL_DIR     :\", VAL_DIR)\n",
    "print(\"REAL_DIR    :\", REAL_DIR)\n",
    "print(\"MODEL_DIR   :\", MODEL_DIR)\n",
    "print(\"LOGS_DIR    :\", LOGS_DIR)\n",
    "print(\"MODEL_REGULAR:\", MODEL_REGULAR)\n",
    "print(\"MODEL_BEST95 :\", MODEL_BEST95)\n",
    "print(\"CLASSES_JSON :\", CLASSES_JSON)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf9aa6-0f1a-46ed-94c2-ac48463d4f2e",
   "metadata": {},
   "source": [
    "**Escaneo de carpetas, construcci√≥n de datasets y class weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f004c-e6a5-4a1a-819a-afbc18ad02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Celda 3B: dataset balanceado + val ====\n",
    "from pathlib import Path\n",
    "import glob, os, json, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# --- usa lo que ya tengas definido ---\n",
    "# TRAIN_DIR, VAL_DIR (o TEST_DIR), IMG_SIZE, BATCH_SIZE\n",
    "# MODEL_DIR, CLASSES_JSON ya vienen de tu Celda 2\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "random.seed(42)\n",
    "\n",
    "IMG_SIZE = (160, 160)  # debe coincidir con tu modelo\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# -------- escaneo de carpetas -> nombres de clases + rutas ----------\n",
    "def canonical_name(parent, child=None):\n",
    "    norm = lambda s: s.strip().replace(\" \", \"_\")\n",
    "    p = norm(parent)\n",
    "    if p.lower().startswith(\"sin\"):\n",
    "        return \"sin_grietas\"\n",
    "    return f\"{p}_{norm(child)}\"\n",
    "\n",
    "def scan_leaf_dirs(root: Path):\n",
    "    # Devuelve: class_names (orden estable) y lista de (files, label)\n",
    "    root = Path(root)\n",
    "    class_to_files = {}\n",
    "    for ptype in sorted([d for d in root.iterdir() if d.is_dir()]):\n",
    "        if ptype.name.lower().startswith(\"sin\"):\n",
    "            files = sum([glob.glob(str(ptype / f\"*{ext}\")) for ext in [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]], [])\n",
    "            if files:\n",
    "                cname = \"sin_grietas\"\n",
    "                class_to_files.setdefault(cname, []).extend(sorted(files))\n",
    "        else:\n",
    "            for sev in sorted([d for d in ptype.iterdir() if d.is_dir()]):\n",
    "                files = sum([glob.glob(str(sev / f\"*{ext}\")) for ext in [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]], [])\n",
    "                if files:\n",
    "                    cname = canonical_name(ptype.name, sev.name)\n",
    "                    class_to_files.setdefault(cname, []).extend(sorted(files))\n",
    "    class_names = sorted(class_to_files.keys())\n",
    "    files = []\n",
    "    labels = []\n",
    "    for i, cname in enumerate(class_names):\n",
    "        fs = class_to_files[cname]\n",
    "        files.extend(fs)\n",
    "        labels.extend([i]*len(fs))\n",
    "    return class_names, files, labels, class_to_files\n",
    "\n",
    "# --- escanea train y val ---\n",
    "class_names, train_files_all, train_labels_all, train_map = scan_leaf_dirs(Path(TRAIN_DIR))\n",
    "_,          val_files_all,   val_labels_all,   _         = scan_leaf_dirs(Path(VAL_DIR))\n",
    "\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(\"Clases:\", NUM_CLASSES, class_names)\n",
    "\n",
    "# ---- guarda clases (para inferencia) ----\n",
    "CLASSES_JSON.write_text(json.dumps({\"class_names\": class_names}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"Clases guardadas en\", CLASSES_JSON)\n",
    "\n",
    "# ------------- muestreo balanceado para train ------------------\n",
    "# objetivo por clase / √©poca\n",
    "TARGET_PER_CLASS = 300\n",
    "CAP_SIN_GRIETAS  = 600  # para sin_grietas permitimos m√°s si quieres\n",
    "IMG_EXTS = [\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"]\n",
    "\n",
    "def make_aug_layer():\n",
    "    return keras.Sequential([\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(0.08),\n",
    "        keras.layers.RandomZoom(0.2),\n",
    "        keras.layers.RandomContrast(0.2),\n",
    "        keras.layers.RandomBrightness(0.2),\n",
    "    ], name=\"aug\")\n",
    "\n",
    "AUG = make_aug_layer()\n",
    "\n",
    "def load_preprocess(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = (img - 0.5) * 2.0\n",
    "    y   = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "    return img, y\n",
    "\n",
    "def load_preprocess_val(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = (img - 0.5) * 2.0\n",
    "    y   = tf.one_hot(label, depth=NUM_CLASSES)\n",
    "    return img, y\n",
    "\n",
    "# construir datasets por clase con oversampling + augment\n",
    "per_class_datasets = []\n",
    "counts = []\n",
    "for cid, cname in enumerate(class_names):\n",
    "    paths = train_map[cname]\n",
    "    n = len(paths)\n",
    "    counts.append(n)\n",
    "    tgt = CAP_SIN_GRIETAS if cname == \"sin_grietas\" else TARGET_PER_CLASS\n",
    "    if n >= tgt:\n",
    "        chosen = random.sample(paths, tgt)\n",
    "    else:\n",
    "        # oversampling con reposici√≥n\n",
    "        chosen = [random.choice(paths) for _ in range(tgt)]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((chosen, [cid]*len(chosen)))\n",
    "    ds = ds.shuffle(len(chosen), seed=42)\n",
    "    ds = ds.map(lambda p,l: load_preprocess(p,l), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(lambda x,y: (AUG(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "    per_class_datasets.append(ds.repeat())\n",
    "\n",
    "print(\"Recuento original por clase:\", dict(zip(class_names, counts)))\n",
    "\n",
    "# mezcla balanceada (cada clase aporta ~1/NUM_CLASSES)\n",
    "train_ds = tf.data.Dataset.sample_from_datasets(per_class_datasets, weights=[1.0/NUM_CLASSES]*NUM_CLASSES, seed=42)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# ----- val ds (sin augment, sin balance) -----\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_files_all, val_labels_all))\n",
    "val_ds = val_ds.map(load_preprocess_val, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890c02b-7915-4624-a60c-c271a782e71e",
   "metadata": {},
   "source": [
    "**Modelo (MobileNetV2 + cabeza densa)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4ba1c-ab86-4209-9100-603169ab1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Celda 4B: Focal Loss + entrenamiento ====\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# calcula alpha (Cui et al. \"effective number of samples\")\n",
    "beta = 0.9999\n",
    "counts_arr = np.array([len(train_map[c]) for c in class_names], dtype=np.float32)\n",
    "eff_num = (1 - np.power(beta, counts_arr)) / (1 - beta)\n",
    "alpha = (np.sum(eff_num) / eff_num)\n",
    "alpha = alpha / np.mean(alpha)  # normaliza\n",
    "alpha_tf = tf.constant(alpha, dtype=tf.float32)\n",
    "print(\"alpha:\", np.round(alpha, 3))\n",
    "\n",
    "def categorical_focal_loss(alpha_vec, gamma=2.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        eps = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        ce = -y_true * tf.math.log(y_pred)\n",
    "        weight = tf.pow(1 - y_pred, gamma) * alpha_vec\n",
    "        return tf.reduce_sum(weight * ce, axis=-1)\n",
    "    return loss\n",
    "\n",
    "# modelo (puedes mantener tu arquitectura actual si ya la tienes)\n",
    "base = keras.applications.MobileNetV2(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=(*IMG_SIZE,3)\n",
    ")\n",
    "base.trainable = False  # warmup\n",
    "x = keras.layers.GlobalAveragePooling2D()(base.output)\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "out = keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = keras.Model(base.input, out, name=\"mansory_mobilenetv2\")\n",
    "\n",
    "loss_fn = categorical_focal_loss(alpha_tf, gamma=2.0)\n",
    "model.compile(optimizer=keras.optimizers.Adam(3e-4), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks\n",
    "es  = keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True, monitor=\"val_accuracy\")\n",
    "rlr = keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5, monitor=\"val_accuracy\")\n",
    "ck  = keras.callbacks.ModelCheckpoint(str(MODEL_REGULAR), monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True, save_weights_only=False)\n",
    "\n",
    "class Save95(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (logs or {}).get(\"val_accuracy\", 0) >= 0.95:\n",
    "            self.model.save(str(MODEL_BEST95), include_optimizer=False)\n",
    "            print(f\"\\n‚úÖ Guardado {MODEL_BEST95} (val_acc ‚â• 95%)\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[es, rlr, ck, Save95()],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# unfreeze fino (opcional): afina √∫ltimas capas si val_acc se estanca\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-40]:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "history2 = model.fit(\n",
    "    train_ds, validation_data=val_ds, epochs=10, callbacks=[es, rlr, ck, Save95()], verbose=1\n",
    ")\n",
    "\n",
    "# guardamos clases de nuevo por si entrenas desde cero\n",
    "CLASSES_JSON.write_text(json.dumps({\"class_names\": class_names}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"\\nClases guardadas en\", CLASSES_JSON)\n",
    "print(\"Modelo mejor por val_acc en:\", MODEL_REGULAR)\n",
    "if Path(MODEL_BEST95).exists():\n",
    "    print(\"Tambi√©n se guard√≥:\", MODEL_BEST95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caef3ea-bda2-4d19-a3bc-f515a4caf757",
   "metadata": {},
   "source": [
    "**Callbacks (EarlyStopping, LR, Checkpoints, ‚â•95%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f376c21a-e358-4cee-bc09-bfadfd459304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: callbacks\n",
    "from datetime import datetime\n",
    "\n",
    "# Guarda siempre el mejor por val_acc\n",
    "ckpt_best = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=str(MODEL_REGULAR),\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping\n",
    "early = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    patience=6,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce LR si no mejora\n",
    "rlrop = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    factor=0.3,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Log a CSV (permite ver progreso y reanudar)\n",
    "csvlog = keras.callbacks.CSVLogger(str(TRAIN_LOG), append=True)\n",
    "\n",
    "# Guardar autom√°ticamente si llega a ‚â•95% val_acc\n",
    "class SaveOn95(keras.callbacks.Callback):\n",
    "    def __init__(self, path, monitor=\"val_acc\", threshold=0.95):\n",
    "        super().__init__()\n",
    "        self.path = str(path)\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.saved = False\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val = logs.get(self.monitor)\n",
    "        if val is not None and val >= self.threshold and not self.saved:\n",
    "            self.model.save(self.path)\n",
    "            self.saved = True\n",
    "            print(f\"\\n‚úÖ Alcanzado {self.monitor} ‚â• {self.threshold:.2f}. Guardado: {self.path}\\n\")\n",
    "\n",
    "class TrainingEndPrinter(keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        if Path(MODEL_BEST95).exists():\n",
    "            print(f\"\\nüéâ Entrenamiento finalizado: se alcanz√≥ ‚â•95% y se guard√≥ {MODEL_BEST95}\")\n",
    "        else:\n",
    "            print(\"\\n‚ÑπÔ∏è Entrenamiento finalizado: no se alcanz√≥ 95%. Revisa el historial y el mejor modelo por val_acc.\")\n",
    "\n",
    "save95 = SaveOn95(MODEL_BEST95, monitor=\"val_acc\", threshold=0.95)\n",
    "cbs = [ckpt_best, early, rlrop, csvlog, save95, TrainingEndPrinter()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2ac2e-2c3e-4729-8cbc-f0c49e048b1a",
   "metadata": {},
   "source": [
    "**Entrenamiento (con reanudaci√≥n si ya hay modelo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c40071bb-2c66-46e2-bf81-c515e41c27de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el mejor modelo previo por val_acc: C:\\Users\\User\\mansory\\modelo_mansory.keras\n",
      "Epoch 1/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - acc: 0.9437 - loss: 0.5380 - top3: 0.9938  \n",
      "Epoch 1: val_acc improved from None to 0.94227, saving model to modelos\\modelo_mansory.keras\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 413ms/step - acc: 0.9432 - loss: 0.5091 - top3: 0.9938 - val_acc: 0.9423 - val_loss: 0.1905 - val_top3: 0.9884 - learning_rate: 3.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - acc: 0.9408 - loss: 0.5066 - top3: 0.9949  \n",
      "Epoch 2: val_acc improved from 0.94227 to 0.94319, saving model to modelos\\modelo_mansory.keras\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 404ms/step - acc: 0.9448 - loss: 0.4693 - top3: 0.9944 - val_acc: 0.9432 - val_loss: 0.1846 - val_top3: 0.9882 - learning_rate: 3.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - acc: 0.9475 - loss: 0.4561 - top3: 0.9966  \n",
      "Epoch 3: val_acc did not improve from 0.94319\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 402ms/step - acc: 0.9467 - loss: 0.4896 - top3: 0.9953 - val_acc: 0.9408 - val_loss: 0.1994 - val_top3: 0.9869 - learning_rate: 3.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - acc: 0.9428 - loss: 0.4547 - top3: 0.9936  \n",
      "Epoch 4: val_acc did not improve from 0.94319\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 408ms/step - acc: 0.9428 - loss: 0.4758 - top3: 0.9941 - val_acc: 0.9412 - val_loss: 0.1961 - val_top3: 0.9869 - learning_rate: 3.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - acc: 0.9442 - loss: 0.4902 - top3: 0.9943  \n",
      "Epoch 5: val_acc did not improve from 0.94319\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 409ms/step - acc: 0.9428 - loss: 0.4786 - top3: 0.9940 - val_acc: 0.9421 - val_loss: 0.1900 - val_top3: 0.9876 - learning_rate: 9.0000e-06\n",
      "Epoch 6/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - acc: 0.9439 - loss: 0.4729 - top3: 0.9945  \n",
      "Epoch 6: val_acc did not improve from 0.94319\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 401ms/step - acc: 0.9444 - loss: 0.4775 - top3: 0.9937 - val_acc: 0.9430 - val_loss: 0.1889 - val_top3: 0.9875 - learning_rate: 9.0000e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - acc: 0.9449 - loss: 0.4770 - top3: 0.9945  \n",
      "Epoch 7: val_acc did not improve from 0.94319\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 400ms/step - acc: 0.9445 - loss: 0.4687 - top3: 0.9943 - val_acc: 0.9430 - val_loss: 0.1880 - val_top3: 0.9878 - learning_rate: 2.7000e-06\n",
      "Epoch 8/30\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - acc: 0.9459 - loss: 0.4588 - top3: 0.9944  \n",
      "Epoch 8: val_acc did not improve from 0.94319\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m1356/1356\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 400ms/step - acc: 0.9455 - loss: 0.4684 - top3: 0.9945 - val_acc: 0.9430 - val_loss: 0.1877 - val_top3: 0.9878 - learning_rate: 2.7000e-06\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "üéâ Entrenamiento finalizado: se alcanz√≥ ‚â•95% y se guard√≥ C:\\Users\\User\\mansory\\modelo_mansory_95.keras\n",
      "\n",
      "Clases guardadas en C:\\Users\\User\\mansory\\classes.json\n",
      "\n",
      "üìà Mejor val_acc (esta sesi√≥n): 0.943\n",
      "Modelo mejor por val_acc en: C:\\Users\\User\\mansory\\modelo_mansory.keras\n",
      "Tambi√©n se guard√≥ (‚â•95%): C:\\Users\\User\\mansory\\modelo_mansory_95.keras\n"
     ]
    }
   ],
   "source": [
    "# Celda 6: entrenamiento\n",
    "\n",
    "# Si ya existe un modelo mejor por val_acc, lo cargamos para reanudar desde ah√≠\n",
    "if MODEL_REGULAR.exists():\n",
    "    print(\"Cargando el mejor modelo previo por val_acc:\", MODEL_REGULAR)\n",
    "    model = keras.models.load_model(MODEL_REGULAR)\n",
    "\n",
    "EPOCHS_TARGET = 30  # intenta llegar hasta aqu√≠ (EarlyStopping puede parar antes)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_TARGET,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar nombres de clases (para inferencia)\n",
    "with open(CLASSES_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"class_names\": class_names}, f, ensure_ascii=False, indent=2)\n",
    "print(\"\\nClases guardadas en\", CLASSES_JSON)\n",
    "\n",
    "# Resumen final .3f}\")\n",
    "print(\"Modelo mejor por val_acc en:\", MODEL_REGULAR)\n",
    "if Path(MODEL_BEST95).exists():\n",
    "    print(\"Tambi√©n se guard√≥ (‚â•95%):\", MODEL_BEST95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f40f8029-d385-4000-bd95-45984475959e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de clases en JSON: 10 ‚Üí C:\\Users\\User\\mansory\\classes.json\n",
      "Modelos encontrados:\n",
      " - C:\\Users\\User\\mansory\\modelo_mansory.keras\n",
      " - C:\\Users\\User\\mansory\\modelo_mansory_95.keras\n",
      " - C:\\Users\\User\\mansory\\modelos\\modelo_mansory.keras\n",
      "   modelo_mansory.keras: salidas=4, input=(160, 160, 3)\n",
      "   modelo_mansory_95.keras: salidas=10, input=(224, 224, 3)\n",
      "\n",
      "‚úÖ Usar√©: C:\\Users\\User\\mansory\\modelo_mansory_95.keras\n",
      "   Tama√±o de entrada esperado: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "# Carpeta base donde est√°n tus archivos (aj√∫stala si fuera distinto)\n",
    "BASE = Path(r\"C:\\Users\\User\\mansory\")\n",
    "\n",
    "# 1) Cargar clases (prioriza el classes.json de la ra√≠z)\n",
    "CLASSES_JSON = BASE / \"classes.json\"\n",
    "if not CLASSES_JSON.exists():\n",
    "    CLASSES_JSON = BASE / \"modelos\" / \"classes.json\"\n",
    "class_names = json.loads(CLASSES_JSON.read_text(encoding=\"utf-8\"))[\"class_names\"]\n",
    "print(\"N¬∫ de clases en JSON:\", len(class_names), \"‚Üí\", CLASSES_JSON)\n",
    "\n",
    "# 2) Listar modelos .keras (en ra√≠z y en /modelos)\n",
    "keras_files = [*BASE.glob(\"*.keras\"), *(BASE/\"modelos\").glob(\"*.keras\")]\n",
    "print(\"Modelos encontrados:\")\n",
    "for kf in keras_files: print(\" -\", kf)\n",
    "\n",
    "# 3) Cargar cada modelo y quedarnos con el que tenga el mismo n¬∫ de salidas\n",
    "picked = None\n",
    "picked_in_size = None\n",
    "for kf in keras_files:\n",
    "    try:\n",
    "        m = keras.models.load_model(kf)\n",
    "        num_out = m.output_shape[-1]\n",
    "        in_shape = m.input_shape[1:4]  # (H, W, C)\n",
    "        print(f\"   {kf.name}: salidas={num_out}, input={in_shape}\")\n",
    "        if num_out == len(class_names):\n",
    "            picked = kf\n",
    "            picked_in_size = (int(in_shape[0]), int(in_shape[1]))\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"   {kf.name}: no se pudo cargar -> {e}\")\n",
    "\n",
    "assert picked is not None, (\n",
    "    \"No encontr√© un .keras con el mismo n√∫mero de clases que tu JSON. \"\n",
    "    \"Deja solo el modelo correcto (de 10 clases) o borra/renombra los viejos.\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Usar√©:\", picked)\n",
    "print(\"   Tama√±o de entrada esperado:\", picked_in_size)\n",
    "\n",
    "# Deja el modelo y tama√±o listos para la siguiente celda\n",
    "MODEL_PATH = picked\n",
    "TARGET_SIZE = picked_in_size\n",
    "model = keras.models.load_model(MODEL_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fc1c68a-9278-4ef1-9d1f-a8acd1d42c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de grieta: sin grietas\n",
      "Severidad: -\n"
     ]
    }
   ],
   "source": [
    "def split_type_severity(name: str):\n",
    "    name = name.strip()\n",
    "    if name.lower().replace(\"__\", \"_\") == \"sin_grietas\":\n",
    "        return \"sin grietas\", \"-\"\n",
    "    parts = name.split(\"_\")\n",
    "    # La √∫ltima palabra es la severidad, lo dem√°s es el tipo\n",
    "    severidad = parts[-1]\n",
    "    tipo = \" \".join(parts[:-1]).replace(\"_\", \" \")\n",
    "    return tipo, severidad\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = load_img(img_path, target_size=TARGET_SIZE)\n",
    "    x = img_to_array(img)\n",
    "    x = x / 255.0\n",
    "    x = (x - 0.5) * 2.0\n",
    "    x = np.expand_dims(x, 0)\n",
    "\n",
    "    pred = model.predict(x, verbose=0)\n",
    "    pred_id = int(np.argmax(pred[0]))\n",
    "    if pred_id >= len(class_names):\n",
    "        raise RuntimeError(\n",
    "            f\"pred_id {pred_id} fuera de rango para {len(class_names)} clases. \"\n",
    "            \"Aseg√∫rate de que el modelo y el JSON corresponden.\"\n",
    "        )\n",
    "    tipo, sev = split_type_severity(class_names[pred_id])\n",
    "    print(f\"Tipo de grieta: {tipo}\\nSeveridad: {sev}\")\n",
    "\n",
    "# Prueba con tu imagen (aj√∫stala si quieres otra)\n",
    "predict_image(BASE / \"grieta-muro.jpg\")\n",
    "# Ejemplos:\n",
    "# predict_image(BASE / \"test\" / \"compresion_vertical_Grave\" / \"55.jpg\")\n",
    "# predict_image(BASE / \"grieta-muro.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78d471-84a4-4331-a595-41c5a3ecf16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mansorytf]",
   "language": "python",
   "name": "conda-env-mansorytf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
